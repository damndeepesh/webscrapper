Metadata-Version: 2.1
Name: ai-web-scraper-cli
Version: 0.1.0
Summary: A CLI tool to scrape websites and extract info using Gemini or Groq.
Home-page: https://github.com/yourusername/ai-web-scraper-cli
Author: Your Name
Author-email: your.email@example.com
License: UNKNOWN
Project-URL: Bug Tracker, https://github.com/yourusername/ai-web-scraper-cli/issues
Description: # AI Web Scraper CLI
        
        A Command-Line Interface (CLI) tool to scrape web pages and extract structured information using either the Google Gemini or Groq AI APIs.
        
        ## Features
        
        *   Scrapes web content using `crawl4ai`.
        *   Integrates with Google Gemini and Groq APIs for information extraction.
        *   Prompts user for API choice (Gemini/Groq).
        *   Securely handles API keys using a `.env` file.
        *   Allows custom prompts for AI extraction.
        *   Designed to be installable as a Python package.
        
        ## Installation
        
        1.  **Clone the repository:**
            ```bash
            git clone https://github.com/yourusername/ai-web-scraper-cli # Replace with your repo URL
            cd ai-web-scraper-cli
            ```
        
        2.  **Create a virtual environment (recommended):**
            ```bash
            python3 -m venv venv
            source venv/bin/activate # On Windows use `venv\Scripts\activate`
            ```
        
        3.  **Install dependencies:**
            ```bash
            pip install -r requirements.txt
            ```
        
        4.  **Install the package in editable mode (for development):**
            ```bash
            pip install -e .
            ```
            Or, for a regular installation:
            ```bash
            pip install .
            ```
        
        ## Configuration
        
        The tool uses a `.env` file to store your API keys securely. When you run the tool for the first time for a specific API (Gemini or Groq), it will prompt you for the key and save it to a `.env` file in the project's root directory.
        
        Alternatively, you can create a `.env` file manually in the project root:
        
        ```
        GEMINI_API_KEY=YOUR_GEMINI_API_KEY
        GROQ_API_KEY=YOUR_GROQ_API_KEY
        ```
        
        Replace `YOUR_GEMINI_API_KEY` and `YOUR_GROQ_API_KEY` with your actual keys.
        
        *   Get Gemini API Key: [Google AI Studio](https://aistudio.google.com/app/apikey)
        *   Get Groq API Key: [Groq Console](https://console.groq.com/keys)
        
        ## Usage
        
        After installation, you can run the tool using the `ai-scrape` command:
        
        ```bash
        ai-scrape --api [gemini|groq] --url <WEBSITE_URL> [--prompt "Your custom extraction prompt"]
        ```
        
        **Examples:**
        
        *   Scrape using Gemini with the default prompt:
            ```bash
            ai-scrape --api gemini --url https://example.com
            ```
        
        *   Scrape using Groq with a custom prompt:
            ```bash
            ai-scrape --api groq --url https://blog.example.com/article --prompt "Extract the author and publication date."
            ```
        
        The tool will first ask for the API type and URL if not provided via options. If the API key is not found in the `.env` file, it will prompt you to enter it.
        
        ## License
        
        This project is licensed under the MIT License - see the LICENSE file for details. # Add a LICENSE file if you choose one
Platform: UNKNOWN
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Intended Audience :: Developers
Classifier: Topic :: Internet :: WWW/HTTP :: Indexing/Search
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Text Processing
Requires-Python: >=3.7
Description-Content-Type: text/markdown
